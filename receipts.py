# -*- coding: utf-8 -*-
"""Receipts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GtSyLDq7CuUK9NSkwHkgbmA5ZJzRU99b
"""

from google.colab import drive
drive.mount('/content/drive')
import glob
import os
os.chdir("drive/My Drive/Receipts")
import nltk
nltk.download('punkt')
import matplotlib.pyplot as plt
import cv2 as cv
import pytesseract
from collections import defaultdict
from nltk.tokenize import word_tokenize
import pandas as pd
from dateparser.search import search_dates
import re
import numpy as np

os.chdir("content/drive/My Drive/Receipts")
a = [os.path.join("drive/My Drive/Receipts",i) for i in glob.glob("*.jpeg")]

img_txt = defaultdict(list)

images = [i for i in glob.glob("*.jpeg")]
img_txt['images'] = images

def getting_text(image_list): # Taking the text from images
  for image in image_list:
    b = cv.imread(image)
    imgray = cv.cvtColor(b, cv.COLOR_BGR2GRAY)
    rtvl, dst = cv.threshold(imgray, 127, 255, 0)
    _,contours, hierarchy = cv.findContours(dst, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE) # Creating contours
    max_block = max(contours,key=cv.contourArea)
    x,y,w,h = cv.boundingRect(max_block)
    text = pytesseract.image_to_string(b[y:y+h,x:x+w]) # Reading the text from the contour
    img_txt['text'].append(text)

getting_text(a)

imgtxt = pd.DataFrame(img_txt)

imgtxt['text'].apply(lambda x: x.replace(' ', '\n'))

punc = list("!@#$%^&*()_~`/><?\ ") # Creating a punctuation list

def cleaning(text): # Cleaning the data
  for i in range(len(text)):
    test = [word for word in word_tokenize(img_txt['text'][i]) if word not in punc]

imgtxt['text'] = imgtxt['text'].apply(lambda x: " ".join([word for word in word_tokenize(x) if word not in punc]))

imgtxt.to_csv('img_txt.csv', escapechar='\n', index=False)

def getting_dates(txt):          # Extracting date from text
  b = search_dates()
  try:
    f = re.search('[0-9].*[0-9]', b[0][0])
    imgtxt['date'].append(f.group())
  except TypeError:
    imgtxt['date'].append(np.nan)